{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'Traindata', 'Testdata'])\n"
     ]
    }
   ],
   "source": [
    "# Load the Lenk dataset\n",
    "lenk_name = \"data/lenk/lenk_data.mat\"\n",
    "lenk_dataset = sio.loadmat(lenk_name)\n",
    "print(lenk_dataset.keys())\n",
    "lenk_train = lenk_dataset['Traindata']\n",
    "lenk_test = lenk_dataset['Testdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 20, 14)\n",
      "(180, 20)\n"
     ]
    }
   ],
   "source": [
    "# Convert Lenk train dataset into T x N x d1 form\n",
    "n_train = np.unique(lenk_train[:, :-1], axis=0).shape[0]\n",
    "tasks = []\n",
    "labels = []\n",
    "for task_begin in range(0, lenk_train.shape[0], n_train):\n",
    "    task_end = task_begin + n_train\n",
    "    task = lenk_train[task_begin:task_end,:-1]\n",
    "    label = lenk_train[task_begin:task_end,-1]\n",
    "    tasks.append(task)\n",
    "    labels.append(label)\n",
    "\n",
    "# Add Lenk test dataset into the mix\n",
    "n_test = np.unique(lenk_test[:, :-1], axis=0).shape[0]\n",
    "task_i = 0\n",
    "for task_begin in range(0, lenk_test.shape[0], n_test):\n",
    "    task_end = task_begin + n_test\n",
    "    task = lenk_test[task_begin:task_end,:-1]\n",
    "    label = lenk_test[task_begin:task_end,-1]\n",
    "    tasks[task_i] = np.vstack((tasks[task_i], task))\n",
    "    labels[task_i] = np.append(labels[task_i], label)\n",
    "    task_i += 1\n",
    "tasks = np.asarray(tasks)\n",
    "print(tasks.shape)\n",
    "labels = np.asarray(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = 180\n",
      "d1 = 14\n"
     ]
    }
   ],
   "source": [
    "# Extract the initial parameters\n",
    "T = tasks.shape[0]\n",
    "d1 = tasks[0].shape[1]\n",
    "print(\"T = {}\".format(T))\n",
    "print(\"d1 = {}\".format(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_Y(task, labels):\n",
    "    d2 = 2 * task.shape[1]\n",
    "    sigma = 100\n",
    "\n",
    "    # Generate the parameters for the transform\n",
    "    sum_phi = np.zeros(d2)\n",
    "    for i in range(task.shape[0]):\n",
    "        vec_operand = np.reshape(task[i], (14, 1)) @ np.reshape(np.transpose(np.array([labels[i], 1])), (1, 2))\n",
    "        vec_op_1 = vec_operand[:,0]\n",
    "        vec_op_2 = vec_operand[:,1]\n",
    "        phi = np.concatenate((vec_op_1, vec_op_2))\n",
    "        sum_phi += phi\n",
    "    avg_phi = np.divide(sum_phi, task.shape[0])\n",
    "    return avg_phi/np.linalg.norm(avg_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose test task and the rest is training\n",
    "test_task = tasks[0]        # Can also choose this randomly\n",
    "test_labels = labels[0]\n",
    "train_tasks = tasks[1:]\n",
    "train_labels = labels[1:]\n",
    "\n",
    "#normalize and create a test evaluation set\n",
    "Y0 = transform_Y(test_task, test_labels)\n",
    "X0 = test_task\n",
    "R0 = test_labels\n",
    "R0 = np.expand_dims(R0, axis=1)\n",
    "#normalize test task\n",
    "normx0 = np.linalg.norm(X0, axis=1).reshape(len(X0),1)\n",
    "#\n",
    "X0new = X0/normx0\n",
    "R0new = R0/normx0\n",
    "# save test task\n",
    "pickle.dump(X0new, open('./data/lenk/X0.pkl', \"wb\"))\n",
    "pickle.dump(Y0, open('./data/lenk/Y0.pkl', \"wb\"))\n",
    "pickle.dump(R0new, open('./data/lenk/R0.pkl', \"wb\"))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training dataset\n",
    "\n",
    "# select 50 tasks uniformly at random from the training tasks\n",
    "indices = np.random.randint(0,T-1,size=50)\n",
    "d2 = 2*d1\n",
    "Ytrain = np.zeros((50,d2))\n",
    "for i in range(50):\n",
    "    X = train_tasks[indices[i]]\n",
    "    labs = train_labels[indices[i]]\n",
    "    Ytrain[i,] = transform_Y(X,labs)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#20 samples from each task in train_tasks\n",
    "Xtrain = np.zeros((50*20, d1))\n",
    "task_function = np.zeros(50*20)\n",
    "Rtrain = np.zeros((50*20,1))\n",
    "\n",
    "for i in range(50):\n",
    "    Xtrain[(20*i):(20*i + 20),] = train_tasks[indices[i]]\n",
    "    task_function[(20*i):(20*i + 20)] = i\n",
    "    Rtrain[(20*i):(20*i + 20)] = np.expand_dims(train_labels[indices[i]],axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "#normalize data\n",
    "normXt = np.linalg.norm(Xtrain, axis=1).reshape(len(Xtrain),1)\n",
    "Xtrain_new = Xtrain/normXt\n",
    "Rtrain_new = Rtrain/normXt\n",
    "\n",
    "# save meta-train dataset\n",
    "pickle.dump(Xtrain_new, open('./data/lenk/X.pkl', \"wb\"))\n",
    "pickle.dump(Ytrain, open('./data/lenk/Y.pkl', \"wb\"))\n",
    "pickle.dump(Rtrain_new, open('./data/lenk/R.pkl', \"wb\"))\n",
    "pickle.dump(task_function, open('./data/lenk/task_function.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an evaluation set for the meta-test task\n",
    "\n",
    "indices = np.random.randint(0,len(X0new),size=8)\n",
    "X0eval = X0new[indices,]\n",
    "R0eval = R0new[indices,]\n",
    "\n",
    "pickle.dump(X0eval, open('./data/lenk/X0eval.pkl', \"wb\"))\n",
    "pickle.dump(R0eval, open('./data/lenk/R0eval.pkl', \"wb\"))\n",
    "\n",
    "#generate test data for 20 different trials and different sizes\n",
    "X0test = X0new[-indices,]\n",
    "R0test = R0new[-indices,]\n",
    "\n",
    "for trial in range(20):\n",
    "    for s in range(2,12,2):\n",
    "        indices = np.random.randint(0, len(X0test), size=s)\n",
    "        cX0 = X0test[indices,]\n",
    "        cR0 = R0test[indices,]\n",
    "        pickle.dump(cX0, open('./data/lenk/' + 'X0_N2_{N2F}_trial_{trialF}.pkl'.format(N2F=s, trialF=trial), 'wb'))\n",
    "        pickle.dump(cR0, open('./data/lenk/' + 'R0_N2_{N2F}_trial_{trialF}.pkl'.format(N2F=s, trialF=trial), 'wb'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Loop over N2 for this new test task\n",
    "parent_dir = \"data/lenk/\"\n",
    "for N2 in range(2, 22, 2):\n",
    "    # Get and store the test data\n",
    "    random_indices = np.random.choice(test_task.shape[0], size=N2, replace=False)\n",
    "    X0 = test_task[random_indices, :]\n",
    "    Y0 = transform_Y(test_task, test_labels) # Independent of X\n",
    "    R0 = test_labels[random_indices]\n",
    "    path = os.path.join(parent_dir, \"N2_{}/\".format(N2))\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "    pickle.dump(X0, open(path + \"X.pkl\", \"wb\"))\n",
    "    pickle.dump(Y0, open(path + \"Y0.pkl\", \"wb\"))\n",
    "    pickle.dump(R0, open(path + \"R0.pkl\", \"wb\"))\n",
    "\n",
    "    # Get and store the training data\n",
    "    d1 = test_task.shape[1]\n",
    "    d2 = 2 * d1\n",
    "    X_full = np.ones((1, d1))\n",
    "    Y_full = np.ones((1, d2))\n",
    "    R_full = np.ones((1, 1))\n",
    "    task_function = []\n",
    "    index_total = 0\n",
    "    for i in range(train_tasks.shape[0]):\n",
    "        Y = transform_Y(train_tasks[i], train_labels[i])\n",
    "        Y_full = np.vstack((Y_full, Y))\n",
    "        for j in range(test_task.shape[0]):\n",
    "            X = train_tasks[i][j]\n",
    "            R = train_labels[i][j]\n",
    "            X_full = np.vstack((X_full, X))\n",
    "            R_full = np.vstack((R_full, R))\n",
    "\n",
    "            prev_index_total = index_total\n",
    "            index_total += X.shape[0]\n",
    "            for j in range(prev_index_total, index_total):\n",
    "                task_function.append(i)\n",
    "\n",
    "    task_function = np.asarray(task_function)\n",
    "    R_full = R_full[1:]     # N x 1\n",
    "    print(R_full.shape)\n",
    "    X_full = X_full[1:]     # N x d1\n",
    "    print(X_full.shape)\n",
    "    Y_full = Y_full[1:]     # T x d2\n",
    "    print(Y_full.shape)\n",
    "    pickle.dump(X_full, open(path + \"X.pkl\", \"wb\"))\n",
    "    pickle.dump(Y_full, open(path + \"Y.pkl\", \"wb\"))\n",
    "    pickle.dump(R_full, open(path + \"R.pkl\", \"wb\"))\n",
    "    pickle.dump(task_function, open(path + \"task_function.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
